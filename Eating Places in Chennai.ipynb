{"cells": [{"metadata": {}, "cell_type": "code", "source": "import requests\nimport pandas as pd\nfrom pandas.io.json import json_normalize\nimport numpy as np\nimport random\nfrom tqdm import tqdm_notebook\nimport folium\nfrom geopy.geocoders import Nominatim\nimport urllib.request\nfrom bs4 import BeautifulSoup\nimport matplotlib.cm as cm\nimport matplotlib.colors as colors\nfrom sklearn.cluster import KMeans\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n#from IPython.display import Image \n#from IPython.core.display import HTML \n#from pandas.io.json import json_normalize", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "Webscraping of data from Wikipedia"}, {"metadata": {}, "cell_type": "code", "source": "url = 'https://en.wikipedia.org/wiki/Areas_of_Chennai'\npage_unparsed = urllib.request.urlopen(url)\nsoup = BeautifulSoup(page_unparsed, 'html.parser')", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "wiki_rows = [] # each row in the wikipedia table\nurls = []\nnames = []\n\nwiki_table = soup.find_all(\"table\", {\"class\": \"wikitable\"})\nfor row in wiki_table:\n  wiki_rows.append(row.find_all('a', href=True))\n\n# gets names and links of each neighborhood so that further scraping can be done\nfor i in range(len(wiki_rows[0])):\n  urls.append('https://en.wikipedia.org' + wiki_rows[0][i]['href'])\n  names.append(wiki_rows[0][i].text)", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "# getting data from each neighborhood\n\nlatitudes = []\nlongitudes = []\npincodes = []\n\nfor url in tqdm_notebook(urls, total = len(urls), unit = 'url'):\n  try: # because some links are broken\n    page_unparsed = urllib.request.urlopen(url)\n    soup = BeautifulSoup(page_unparsed, 'html.parser')\n  except:\n    continue\n\n  coords = soup.find(\"span\", {\"class\" : \"geo-dec\"})\n  pincode = soup.find(\"div\", {\"class\" : \"postal-code\"})\nif coords == None:  # because some pages do not have coordinates listed\n    latitudes.append(np.nan)\n    longitudes.append(np.nan)\n\n  else:\n    coords = coords.text.split()\n    latitudes.append(float(coords[0].replace('N', '').replace('\u00b0', '')))\n    longitudes.append(float(coords[1].replace('E', '').replace('\u00b0', '')))", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "neighborhoods = pd.DataFrame(list(zip(names, latitudes, longitudes)), columns =['Name', 'Latitude', 'Longitude']) \nneighborhoods = neighborhoods[neighborhoods['Latitude'].notnull()]\nneighborhoods = neighborhoods[neighborhoods['Longitude'].notnull()]\nneighborhoods.head()", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "Foursquare\nUsing Foursquare, individual neighboords are searched to find nearby venues and their categories withing a 500m radius of a randomnly chosen neighborhood, Adyar.\n"}, {"metadata": {}, "cell_type": "code", "source": "CLIENT_ID = 'LDSODETW2HHHFM3RBS3VEN4ZHF1ZU05FCD11PDTBBAT1YR3U' # your Foursquare ID\nCLIENT_SECRET = 'KTYUBVGXKJY1FPY2YAWEXCWVM1R5EXR5TZMDOSYIMVYXSFN' # your Foursquare Secret\nVERSION = '20180605'", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "neighborhood_latitude = neighborhoods[neighborhoods['Name'] == 'Choolaimedu']['Latitude']\nneighborhood_longitude = neighborhoods[neighborhoods['Name'] == 'Choolaimedu']['Longitude']\n\nurl = 'https://api.foursquare.com/v2/venues/explore?&client_id={}&client_secret={}&v={}&ll={},{}&radius={}&limit={}'.format(\n    CLIENT_ID[::-1], \n    CLIENT_SECRET[::-1], \n    VERSION, \n    neighborhood_latitude, \n    neighborhood_longitude, \n    radius, \n    LIMIT)\n\nresults = requests.get(url).json()", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "def get_category_type(row):\n    try:\n        categories_list = row['categories']\n    except:\n        categories_list = row['venue.categories']\n        \n    if len(categories_list) == 0:\n        return None\n    else:\n        return categories_list[0]['name']", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "LIMIT = 100 # limit of number of venues returned by Foursquare API\nradius = 500 # \n\ndef getNearbyVenues(names, latitudes, longitudes, radius=500):\n    venues_list = []\n    for name, lat, lng in tqdm_notebook(zip(names, latitudes, longitudes), total = neighborhoods.shape[0], unit = 'neighborhoods'):\n        # print(name)\nurl = 'https://api.foursquare.com/v2/venues/explore?&client_id={}&client_secret={}&v={}&ll={},{}&radius={}&limit={}'.format(\n            CLIENT_ID[::-1], \n            CLIENT_SECRET[::-1], \n            VERSION, \n            lat, \n            lng, \n            radius, \n            LIMIT)\n            \n        # make the GET request\n        results = requests.get(url).json()[\"response\"]['groups'][0]['items']\n                url = 'https://api.foursquare.com/v2/venues/explore?&client_id={}&client_secret={}&v={}&ll={},{}&radius={}&limit={}'.format(\n            CLIENT_ID[::-1], \n            CLIENT_SECRET[::-1], \n            VERSION, \n            lat, \n            lng, \n            radius, \n            LIMIT)\n            \n        # make the GET request\n        results = requests.get(url).json()[\"response\"]['groups'][0]['items']\n        \n# return only relevant information for each nearby venue\n        venues_list.append([(\n            name, \n            lat, \n            lng, \n            v['venue']['name'], \n            v['venue']['categories'][0]['id'],\n            v['venue']['location']['lat'], \n            v['venue']['location']['lng'],  \n            v['venue']['categories'][0]['name']) for v in results])\n    return(nearby_venues)\n    nearby_venues = pd.DataFrame([item for venue_list in venues_list for item in venue_list])\n    nearby_venues.columns = ['Neighborhood', \n                  'Neighborhood Latitude', \n                  'Neighborhood Longitude', \n                  'Venue', \n                  'Venue ID',\n                  'Venue Latitude', \n                  'Venue Longitude', \n                  'Venue Category']\n    return(nearby_venues)", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "chennai_venues = getNearbyVenues(names = neighborhoods['Name'],\n                                   latitudes = neighborhoods['Latitude'],\n                                   longitudes = neighborhoods['Longitude'])\nchennai_venues.head()", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "Methodology - One hot encoding."}, {"metadata": {}, "cell_type": "code", "source": "chennai_onehot = pd.get_dummies(chennai_venues[['Venue Category']], prefix=\"\", prefix_sep=\"\")\nchennai_onehot['Neighborhood'] = chennai_venues['Neighborhood'] \nfixed_columns = [chennai_onehot.columns[-1]] + list(chennai_onehot.columns[:-1])\nchennai_onehot = chennai_onehot[fixed_columns]\nchennai_onehot.head()", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "chennai_grouped = chennai_onehot.groupby('Neighborhood').mean().reset_index()\nchennai_grouped", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "Get the most frequent venues in each neighborhood."}, {"metadata": {}, "cell_type": "code", "source": "def return_most_common_venues(row, num_top_venues):\n    row_categories = row.iloc[1:]\n    row_categories_sorted = row_categories.sort_values(ascending=False)\n    \n    return row_categories_sorted.index.values[0:num_top_venues]\n\nnum_top_venues = 10\n\nindicators = ['st', 'nd', 'rd']\n\n# create columns according to number of top venues\ncolumns = ['Neighborhood']\nfor ind in np.arange(num_top_venues):\n    try:\n        columns.append('{}{} Most Common Venue'.format(ind+1, indicators[ind]))\n    except:\n        columns.append('{}th Most Common Venue'.format(ind+1))\n\n# create a new dataframe\nneighborhoods_venues_sorted = pd.DataFrame(columns=columns)\nneighborhoods_venues_sorted['Neighborhood'] = chennai_grouped['Neighborhood']\n\nfor ind in np.arange(chennai_grouped.shape[0]):\n    neighborhoods_venues_sorted.iloc[ind, 1:] = return_most_common_venues(chennai_grouped.iloc[ind, :], num_top_venues)\n\nneighborhoods_venues_sorted.head()", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "# set number of clusters\nkclusters = 4\n\nchennai_grouped_clustering = chennai_grouped.drop('Neighborhood', 1)\n\n# run k-means clustering\nkmeans = KMeans(n_clusters=kclusters, random_state=0).fit(chennai_grouped_clustering)\n\n# add clustering labels\nneighborhoods_venues_sorted.insert(0, 'Cluster Labels', kmeans.labels_)\nchennai_merged = neighborhoods\n\n# merge toronto_grouped with toronto_data to add latitude/longitude for each neighborhood\nchennai_merged = chennai_merged.join(neighborhoods_venues_sorted.set_index('Neighborhood'), on='Name')\n\nchennai_merged.head() # check the last columns!", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "chennai_merged = chennai_merged[chennai_merged['Cluster Labels'].notnull()]\n\n# create map\nmap_clusters = folium.Map(location=[13.067439, 80.237617], zoom_start=11)\n\n# set color scheme for the clusters\n'''\nx = np.arange(kclusters)\nys = [i + x + (i*x)**2 for i in range(kclusters+1)]\ncolors_array = cm.hsv(np.linspace(0, 1, len(ys)))\nhsv = [colors.rgb2hex(i) for i in colors_array]\n'''\n\ncolors = [\"#ff0000\", \"#3d84ad\", \"#000000\", \"#ffff00\"]\n\n# add markers to the map\nmarkers_colors = []\nfor lat, lon, poi, cluster in zip(chennai_merged['Latitude'], chennai_merged['Longitude'], chennai_merged['Name'], chennai_merged['Cluster Labels']):\n    label = folium.Popup(str(poi) + ' Cluster ' + str(cluster), parse_html=True)\n    folium.CircleMarker(\n        [lat, lon],\n        radius=5,\n        popup=label,\n        color=colors[int(cluster)],\n        fill=True,\n        fill_color=colors[int(cluster)],\n        fill_opacity=0.7).add_to(map_clusters)\n       \n\nmap_clusters", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "chennai_merged.loc[chennai_merged['Cluster Labels'] == 0, chennai_merged.columns[[0] + list(range(4, chennai_merged.shape[1]))]]['1st Most Common Venue'].value_counts().head()", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "chennai_merged.loc[chennai_merged['Cluster Labels'] == 1, chennai_merged.columns[[0] + list(range(4, chennai_merged.shape[1]))]]['1st Most Common Venue'].value_counts().head()", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "chennai_merged.loc[chennai_merged['Cluster Labels'] == 2, chennai_merged.columns[[0] + list(range(4, chennai_merged.shape[1]))]]", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "chennai_merged.loc[chennai_merged['Cluster Labels'] == 3, chennai_merged.columns[[0] + list(range(4, chennai_merged.shape[1]))]]['1st Most Common Venue'].value_counts().head()", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "\nResults\n\nThe following bar graph shows that Cluster 1 has the most number of restaurants."}, {"metadata": {}, "cell_type": "code", "source": "clus1 = pd.DataFrame(pd.DataFrame(list(chennai_merged[chennai_merged['Cluster Labels'] == 0].iloc[:, 4:15].values.ravel()), columns = ['venue_count'])['venue_count'].value_counts()[:6])\n\nflatui = [\"#9b59b6\", \"#3498db\", \"#95a5a6\", \"#e74c3c\", \"#34495e\", \"#2ecc71\"]\nfig, ax = plt.subplots(figsize=(12, 9))\nax = sns.barplot(x = clus1.index, y = clus1['venue_count'], palette=(flatui))\nax.set_xticklabels(ax.get_xticklabels(), rotation = 30,  fontsize = 15)\nax.yaxis.label.set_size(15)\nplt.title('Most frequent venues in cluster 0', fontsize = 15)\nplt.show()", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "The bar graphs for the rest of the clusters show that they do not have any significant similarities between each other.", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "clus1 = pd.DataFrame(pd.DataFrame(list(chennai_merged[chennai_merged['Cluster Labels'] == 1].iloc[:, 4:15].values.ravel()), columns = ['venue_count'])['venue_count'].value_counts()[:6])\nclus2 = pd.DataFrame(pd.DataFrame(list(chennai_merged[chennai_merged['Cluster Labels'] == 2].iloc[:, 4:15].values.ravel()), columns = ['venue_count'])['venue_count'].value_counts()[:6])\nclus3 = pd.DataFrame(pd.DataFrame(list(chennai_merged[chennai_merged['Cluster Labels'] == 3].iloc[:, 4:15].values.ravel()), columns = ['venue_count'])['venue_count'].value_counts()[:6])\n\nflatui = [\"#9b59b6\", \"#3498db\", \"#95a5a6\", \"#e74c3c\", \"#34495e\", \"#2ecc71\"]\nfig, ax = plt.subplots(2,2, figsize = (20, 18))\n\nplt.subplot(2, 2, 1)\nax = sns.barplot(x = clus1.index, y = clus0['venue_count'], palette=(flatui))\nax.set_xticklabels(ax.get_xticklabels(), rotation = 30)\nplt.title('Most frequent venues in cluster 1')\n\nplt.subplot(2, 2, 2)\nax = sns.barplot(x = clus2.index, y = clus2['venue_count'], palette=(flatui))\nax.set_xticklabels(ax.get_xticklabels(), rotation = 30)\nplt.title('Most frequent venues in cluster 2')\n\nplt.subplot(2, 2, 3)\nax = sns.barplot(x = clus3.index, y = clus3['venue_count'], palette=(flatui))\nax.set_xticklabels(ax.get_xticklabels(), rotation = 30)\nplt.title('Most frequent venues in cluster 3', )\n\n\nplt.show()", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "Conclusion and Discussion ", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "chennai_venues['Venue Category'].value_counts()", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "There are quite a number of restaurants in Chennai so any new visitor will not have any issue in finding good places to eat", "execution_count": null, "outputs": []}], "metadata": {"kernelspec": {"name": "python3", "display_name": "Python 3.7", "language": "python"}, "language_info": {"name": "python", "version": "3.7.10", "mimetype": "text/x-python", "codemirror_mode": {"name": "ipython", "version": 3}, "pygments_lexer": "ipython3", "nbconvert_exporter": "python", "file_extension": ".py"}}, "nbformat": 4, "nbformat_minor": 1}